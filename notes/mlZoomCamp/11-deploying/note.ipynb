{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb7bfdc7",
   "metadata": {},
   "source": [
    "How to use ML model for the web?\n",
    "\n",
    "1. train model in notebook and save in file\n",
    "2. load model in a service\n",
    "3. then other services can call the service with the ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd93c087",
   "metadata": {},
   "source": [
    "We will put the churn prediction model and put it in a flask web service, then we put it in a pipenv and then put that in a docker.\n",
    "\n",
    "so from inside to out:\n",
    "- model\n",
    "- flask service\n",
    "- pipenv\n",
    "- docker\n",
    "- cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef4852e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the important code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    " \n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c0f01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    " \n",
    "df = pd.read_csv('../data/churn.csv')\n",
    " \n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    " \n",
    "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    " \n",
    "for c in categorical_columns:\n",
    "    df[c] = df[c].str.lower().str.replace(' ', '_')\n",
    " \n",
    "df.totalcharges = pd.to_numeric(df.totalcharges, errors='coerce')\n",
    "df.totalcharges = df.totalcharges.fillna(0)\n",
    " \n",
    "df.churn = (df.churn == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13d72007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fbded81",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['tenure', 'monthlycharges', 'totalcharges']\n",
    " \n",
    "categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',\n",
    "       'phoneservice', 'multiplelines', 'internetservice',\n",
    "       'onlinesecurity', 'onlinebackup', 'deviceprotection', 'techsupport',\n",
    "       'streamingtv', 'streamingmovies', 'contract', 'paperlessbilling',\n",
    "       'paymentmethod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee937a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    " \n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    " \n",
    "    model = LogisticRegression(C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    " \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74812dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "     dicts = df[categorical + numerical].to_dict(orient='records')\n",
    " \n",
    "     X = dv.transform(dicts)\n",
    "     y_pred = model.predict_proba(X)[:,1]\n",
    " \n",
    "     return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f67679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1.0\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "932ebb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\files\\repos\\leaning-in-public\\notes\\mlZoomCamp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\danie\\files\\repos\\leaning-in-public\\notes\\mlZoomCamp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\danie\\files\\repos\\leaning-in-public\\notes\\mlZoomCamp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.0 0.842 +- 0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\files\\repos\\leaning-in-public\\notes\\mlZoomCamp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)  \n",
    " \n",
    "scores = []\n",
    " \n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    " \n",
    "    y_train = df_train.churn.values\n",
    "    y_val = df_val.churn.values\n",
    " \n",
    "    dv, model = train(df_train, y_train, C=C)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    " \n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    " \n",
    "print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))\n",
    " \n",
    "# Output: C=1.0 0.841 +- 0.008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a932610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\files\\repos\\leaning-in-public\\notes\\mlZoomCamp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8583327916626041"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model = train(df_full_train, df_full_train.churn.values, C=1.0)\n",
    "y_pred = predict(df_test, dv, model)\n",
    "y_test = df_test.churn.values\n",
    " \n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "auc\n",
    " \n",
    "# Output: 0.8572386167896259"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94457301",
   "metadata": {},
   "source": [
    "# previous code is done, now we need to save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f015006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use pickle\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91860616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_C=1.0.bin'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we make the output file\n",
    "\n",
    "output_file = f\"model_C={C}.bin\"\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b0f8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we write the file in th emodel\n",
    "\n",
    "with open(output_file, 'wb') as f_out: #wb for write byte\n",
    "    pickle.dump((dv,model), f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64bd6b2",
   "metadata": {},
   "source": [
    "now we load the model with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc899405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_file = f\"model_C={C}.bin\"\n",
    "\n",
    "\n",
    "with open(model_file, 'rb') as f_in: #rb is read byte\n",
    "    dv, model = pickle.load(f_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7dba153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use this customer\n",
    "\n",
    "customer = {\n",
    "    'gender': 'female',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'yes',\n",
    "    'dependents': 'no',\n",
    "    'phoneservice': 'no',\n",
    "    'multiplelines': 'no_phone_service',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'no',\n",
    "    'onlinebackup': 'yes',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'no',\n",
    "    'streamingtv': 'no',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'month-to-month',\n",
    "    'paperlessbilling': 'yes',\n",
    "    'paymentmethod': 'electronic_check',\n",
    "    'tenure': 1,\n",
    "    'monthlycharges': 29.85,\n",
    "    'totalcharges': 29.85\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7050cc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.627656987858)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dv.transform([customer])\n",
    "model.predict_proba(X)[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a59346b",
   "metadata": {},
   "source": [
    "# it is better to make a seperate script, so we will do that \n",
    "\n",
    "to do so, download the notebook as a py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a46d9d",
   "metadata": {},
   "source": [
    "we can see that now we have a predict.py and a train.py\n",
    "\n",
    "Now we can make the flask server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7e1dfc",
   "metadata": {},
   "source": [
    "# now we need to serve the model over our flask server that we made.\n",
    "\n",
    "we want our backend service to be able to call our churn service on the /predict route\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d14cd79",
   "metadata": {},
   "source": [
    "1. we start by making a predict function in our predict script \n",
    "2. the input is a json and the result will be in json too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dffc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to test it, use requests\n",
    "import requests\n",
    "\n",
    "url = \"\"\n",
    "requests.post(url, json=customer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c049d3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18ac118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
